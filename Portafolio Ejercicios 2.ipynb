{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e08f68",
   "metadata": {},
   "source": [
    "<div style=\"background:#5D6D7E;padding:20px;color:#ffffff;margin-top:10px;\">\n",
    "\n",
    "# NLP - Portafolio de Ejercicios 2\n",
    "\n",
    "## Profesora: Lisibonny Beato\n",
    "### Período 3-2024-2025</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando algunas librerias\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ef769",
   "metadata": {},
   "source": [
    "# Utilizando el archivo de noticias de ESPN que recopiló en una actividad pasada, realice las siguientes tareas de preprocesamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebd3b5",
   "metadata": {},
   "source": [
    "## 1. Lematización y Stemming\n",
    "### Puntuación máxima de la tarea: 1\n",
    "#### Después de haber eliminado los signos de puntuación y las palabras vacías de su corpus, tokenizelo y con estos tokens guarde en dos listas distintas los tokens lematizados y los tokens luego de obtenida su raiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2907f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f70b865",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFE0;padding:20px;color:#000000;margin-top:10px;\">\n",
    "Utilice esta celda para colocar comentarios en el notebook, cuando lo estime necesario. Copiela varias veces donde considere.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d2ba20",
   "metadata": {},
   "source": [
    "## 2. Etiquetado gramatical\n",
    "### Puntuación máxima de la tarea: 1\n",
    "#### Etiquete gramaticalmente su corpus y guarde el resultado en un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc13eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5ed094c",
   "metadata": {},
   "source": [
    "## 3. Taxonomías\n",
    "### Puntuación máxima de la tarea: 1\n",
    "#### Para los synsets de los tokens que estén disponibles, obtenga los hiperónimos de los mismos. Tome en cuenta que debe tomar para cada token el primer synset que se encuentre para la etiqueta gramatical que se determinó para el token en el punto anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223992e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d803e21",
   "metadata": {},
   "source": [
    "## 4. N-Gramas\n",
    "### Puntuación máxima de la tarea: 2\n",
    "#### Desarrolle una función que obtenga todos los ngramas de un corpus para un tamaño (n) en especificado. Haga diversas pruebas sobre la función utilizando su conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec64c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68574439",
   "metadata": {},
   "source": [
    "## 5. Representaciones de Texto Básicas\n",
    "### Puntuación máxima de la tarea: 4\n",
    "#### Represente su colección de documentos como vectores, utilizando one-hot-encoding, bag of words y tf-idf. Hágalo para los documentos en formato tokenizado, lematizado, stemmizado y bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9e587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f662091c",
   "metadata": {},
   "source": [
    "## 6. Representación de Texto mediante Word Embeddings\n",
    "### Puntuación máxima de la tarea: 5\n",
    "#### Se le da un codigo para que haga pruebas sobre word embeddings usando el famoso modelo preentrenado WordtoVec. Represente sus textos mediante Word Embeddings, entrenando los mismos sobre su propia colección de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec(sentences=common_texts, size=5, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dce988",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=model.wv['human']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar=model.wv.most_similar('human',topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc44ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3dc266c",
   "metadata": {},
   "source": [
    "## 7. Profundizando sobre Word Embeddings\n",
    "### Puntuación máxima de la tarea: 6\n",
    "####  Investigue más en profundidad la librería gensim. Puede encontrar más detalles aquí: https://radimrehurek.com/gensim/models/word2vec.html, pero siéntase libre de usar otras fuentes\n",
    "#### De manera especial preste atención a lo siguiente: guardado de modelos para entrenamientos futuros, KeyedVectors para mejorar eficiencia y modelos de Word Embeddings pre-entrenados. Debe aplicar todos estos conceptos para realizar una nueva representación de su colección de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f297c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
